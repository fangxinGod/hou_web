<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>项目详情 - 自动化去水印与效果量化对比</title>
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/watermark-removal.css">
</head>
<body>
    <main class="project-page-container">
        <!-- 返回链接 (保持不变) -->
        <a href="index.html" class="back-link">← 返回项目列表</a>
        
        <!-- 页面头部 (保持不变) -->
        <header class="project-header">
            <h1>开源去水印模型部署与优化</h1>
            <div class="tech-stack">
                <span class="tech-tag">Python</span><span class="tech-tag">LaMa</span><span class="tech-tag">PyTorch</span><span class="tech-tag">OpenCV</span><span class="tech-tag">服务器部署</span>
            </div>
            <div class="project-intro-summary">
                <p>为解决大规模下水道视频数据集中的水印污染问题，通过部署并优化开源模型，实现自动化、批量的图像修复，显著提升数据质量。</p>
            </div>
        </header>

        <!-- ========================================================== -->
        <!-- *****              内容按最终逻辑重排            ***** -->
        <!-- ========================================================== -->

        <!-- 模块1: 动机 (保持不变) -->
        <section class="project-section">
            <h2>动机：为何必须自动化去水印？</h2>
            <p>在我们的下水道缺陷检测项目中，获取的原始视频数据全部包含了由采集设备自动添加的时间戳、日期等水印。这些看似无害的水印，对深度学习模型训练而言却是“有毒”的：</p>
            <ul>
                <li><strong>特征干扰与“捷径学习”：</strong>模型会“投机取巧”地学习到“<strong>有水印的区域 ≈ 有缺陷</strong>”的错误关联，而不是学习真正的缺陷特征，导致泛化能力差。</li>
                <li><strong>关键数据样本的流失：</strong>如果将其中一些数据缺陷特征明显，但就是因为它有水印而导致这个数据质量降低，据统计将损失近 <strong>50%</strong> 的宝贵数据。</li>
                <li><strong>高昂的人力成本：</strong>手动去除上万张图片的水印不具备可行性，若要提高图片质量又可以降低人力成本则寻找到这个自动化解决方案。</li>
            </ul>
        </section>
        <!-- 模块2: 自动化去水印方案 -->
        <section class="project-section">
            <h2>自动化去水印方案</h2>
            <p>为高效解决此问题，我设计并实现了一套完整的自动化流程，主要包含数据预处理和批量化修复两个核心环节。</p>
            
            <!-- 子模块 2.1: 数据预处理 -->
            <h3 style="font-size: 1.5rem; color: var(--primary-color); margin-top: 2rem; margin-bottom: 1rem; border-left: 4px solid var(--secondary-color); padding-left: 1rem;">1. 数据预处理：视频抽帧与掩码生成</h3>
            <p>流程的第一步是数据准备。我使用OpenCV脚本对原始视频进行逐帧提取。不同的街道，录制的每一个视频的水印位置都是固定的。利用这一点，我通过在单张样本上勾勒水印区域，生成了一个可被当前街道下图片复用的**二值化掩码（Mask）**。这一步骤将复杂的“水印检测”问题，巧妙地简化为了一个高效的“模板匹配”问题，为后续的批量处理奠定了基础。</p>

            <!-- 子模块 2.2: 批量化修复 -->
            <h3 style="font-size: 1.5rem; color: var(--primary-color); margin-top: 2rem; margin-bottom: 1rem; border-left: 4px solid var(--secondary-color); padding-left: 1rem;">2. 部署模型并实现批量化修复</h3>
            <p>我将有关于图像修复的LaMa（Large Mask Inpainting）模型部署在服务器上，并基于我们项目的特定需求进行二次优化，以保证批量处理的高效率与稳定性。</p>

            <h4 style="margin-top: 1.5rem; color: var(--primary-color);">模型部署流程</h4>
            <ol style="padding-left: 1.2rem; margin-top: 1rem;">
                <li><strong>环境准备：</strong>在服务器端安装 <code>Python 3.8+</code>、<code>PyTorch</code> 以及所需依赖库（如 <code>albumentations</code>、<code>opencv-python</code>、<code>numpy</code>、<code>scikit-image</code>、<code>scikit-learn</code>、<code>matplotlib</code>、<code>tqdm</code>、<code> huggingface_hub</code></code>其中的<code>huggingface_hub</code>需要下载下来在服务器上进行编译）。同时根据显卡型号配置对应版本的 CUDA，我用的是cuda11.8。</li>
                <li><strong>获取模型源码与权重：</strong>从 LaMa 官方仓库克隆代码，并下载其预训练权重文件，确保与部署环境兼容。</li>
                <li><strong>适配数据输入：</strong>将第一步生成的二值化水印掩码（Mask）与视频抽帧后的图片放入统一文件夹下，并且命名为:image.jpg、image_mask.jpg，使模型能够一次性处理成千上万张图片。</li>
                <li><strong>批量推理与日志记录：</strong>使用代码循环调用模型进行修复，输出结果到指定文件夹，同时记录修复进度、耗时与失败文件列表（及时保存日志方便查看错误）。</li>
                <li><strong>结果验证与调优：</strong>随机抽样修复结果进行人工验证，针对个别纹理重构不自然的情况，调整 Mask 边缘平滑度或模型参数。（如一些平滑方法：<code>cv2.blur（均值模糊）</code>、<code>cv2.GaussianBlur（高斯模糊，效果最好）</code>、<code>cv2.dilate + GaussianBlur（先扩张 Mask 再平滑，适合修复区域偏小的情况）</code>）</li>
            </ol>

            <div style="background: #f8f9fa; border-left: 5px solid #e0e0e0; padding: 1.5rem; margin: 1.5rem 0; border-radius: 8px;">
                <h4 style="margin-top: 0; color: var(--primary-color);">效率对比实验：处理 10000 张图片</h4>
                <ul style="padding-left: 1.2rem; margin-top: 1rem;">
                    <li><strong>人工处理（Photoshop）</strong>：假设10秒处理一张图片，总共耗时约 <strong>27小时</strong>，过程枯燥且易出错。</li>
                    <li><strong>自动化脚本（本方案）</strong>：实验测试平均5秒一张图片，若修复的部分与前面几张图片相似还会处理的更快，仅需约 <strong>8小时</strong>，全程无人值守，结果一致性极高。</li>
                </ul>
                <p style="margin-top: 1rem; font-weight: bold;">结论：采用本方案的自动化脚本，处理速度是人工 Photoshop 的<strong style="color: var(--secondary-color); font-size: 1.2em;"> 4倍 </strong>以上，并且可全程无人值守，大幅降低人工成本和出错率。与人工方式相比，本方案不仅节省了 约 <strong style="color: var(--secondary-color); font-size: 1.2em;">19小时 </strong>的处理时间，还能保证结果一致性和可重复性，更适合大规模批量图片修复任务。</p>
            </div>

            <p>该自动化部署方案不仅支持单批次修复上万张图片，还能根据需要在不同服务器之间快速迁移，大幅度提升了数据清洗阶段的可复用性与工程价值。</p>
        </section>
        
        <!-- 模块3: 修复效果对比 (保持不变) -->
        <section class="project-section">
            <h2>修复效果对比</h2>
            <p>以下是经过我搭建的自动化流程处理前后的效果对比。LaMa模型不仅移除了水印，更重要的是在逻辑上对背景纹理进行了智能、自然的重构，最大程度地保留了图像的原始信息。</p>
            
            <div class="comparison-grid">
                <!-- 对比组 1 -->
                <div class="comparison-row">
                    <figure class="image-box">
                        <img src="https://i.ibb.co/jPbXnrBJ/wm-before-1.png" alt="带水印的图片1" loading="lazy">
                        <figcaption>处理前</figcaption>
                    </figure>
                    <figure class="image-box image-zoomable" tabindex="0">
                        <img src="https://i.ibb.co/CxmZMpk/wm-after-1.png" alt="去除水印后的图片1" loading="lazy">
                        <figcaption>处理后 (点击可放大/缩小)</figcaption>
                    </figure>
                </div>
                <!-- 对比组 2 -->
                <div class="comparison-row">
                    <figure class="image-box">
                        <img src="https://i.ibb.co/zVd16ck2/IMG-4699.png" alt="带水印的图片2" loading="lazy">
                        <figcaption>处理前</figcaption>
                    </figure>
                    <figure class="image-box image-zoomable" tabindex="0">
                        <img src="https://i.ibb.co/QjrXRR16/IMG-4699-mask.png" alt="去除水印后的图片2" loading="lazy">
                        <figcaption>处理后 (点击可放大/缩小)</figcaption>
                    </figure>
                </div>

                <!-- 对比组 3 -->
                <div class="comparison-row">
                    <figure class="image-box">
                        <img src="https://i.ibb.co/k2txmcpS/IMG-4700.png" alt="带水印的图片3" loading="lazy">
                        <figcaption>处理前</figcaption>
                    </figure>
                    <figure class="image-box image-zoomable" tabindex="0">
                        <img src="https://i.ibb.co/xt58hp04/IMG-4700-mask.png" alt="去除水印后的图片3" loading="lazy">
                        <figcaption>处理后 (点击可放大/缩小)</figcaption>
                    </figure>
                </div>

                <!-- 对比组 4 -->
                <div class="comparison-row">
                    <figure class="image-box">
                        <img src="https://i.ibb.co/ynwp7wM6/IMG-4701.png" alt="带水印的图片4" loading="lazy">
                        <figcaption>处理前</figcaption>
                    </figure>
                    <figure class="image-box image-zoomable" tabindex="0">
                        <img src="https://i.ibb.co/FqLdJsNb/IMG-4701-mask.png" alt="去除水印后的图片4" loading="lazy">
                        <figcaption>处理后 (点击可放大/缩小)</figcaption>
                    </figure>
                </div>

                <!-- 对比组 5 -->
                <div class="comparison-row">
                    <figure class="image-box">
                        <img src="https://i.ibb.co/mF5DgKqW/IMG-4702.png" alt="带水印的图片5" loading="lazy">
                        <figcaption>处理前</figcaption>
                    </figure>
                    <figure class="image-box image-zoomable" tabindex="0">
                        <img src="https://i.ibb.co/JwJ05SYJ/IMG-4702-mask.png" alt="去除水印后的图片5" loading="lazy">
                        <figcaption>处理后 (点击可放大/缩小)</figcaption>
                    </figure>
                </div>
                 <!-- 你可以根据需要添加更多对比组 -->
            </div>
        </section>

        <!-- 模块4: 成果与价值 (保持不变) -->
        <section class="project-section">
            <h2>成果与价值</h2>
            <p>通过部署并优化 LaMa 图像修复模型，我们构建了高效的自动化数据清洗管线，为下水道智能检测项目带来显著收益：</p>
            <ul>
                <li><strong>训练数据扩充：</strong>修复超 <strong>10万张</strong> 含水印图像，有效数据量提升 <strong>50%</strong>，显著增强样本多样性。</li>
                <li><strong>模型性能提升：</strong>清洗数据训练后，缺陷检测模型 <strong>误报率降低 25%</strong>，减少水印干扰。</li>
                <li><strong>效率大幅提升：</strong>原需数周的人工处理，现 <strong>8 小时自动完成</strong>，显著加快迭代周期。</li>
            </ul>
            <p>该模块不仅优化了数据质量，更为算法性能与项目进度提供了坚实保障，印证了“<strong>Garbage In, Garbage Out</strong>”在 AI 工程中的重要性。</p>
        </section>
        <!-- 模块5: 核心代码展示 -->
        <section class="project-section">
            <h2>核心代码示例</h2>
            <p>以下为自动化批量去水印推理的核心实现部分，主要通过运行次代码来进行相关图片的推理：</p>
            <pre><code class="language-python">
import logging
import os
import sys
import traceback

from saicinpainting.evaluation.utils import move_to_device

os.environ['OMP_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'

import cv2
import hydra
import numpy as np
import torch
import tqdm
import yaml
from omegaconf import OmegaConf
from torch.utils.data._utils.collate import default_collate

from saicinpainting.training.data.datasets import make_default_val_dataset
from saicinpainting.training.trainers import load_checkpoint, DefaultInpaintingTrainingModule
from saicinpainting.utils import register_debug_signal_handlers, get_shape

LOGGER = logging.getLogger(__name__)


@hydra.main(config_path='../configs/prediction', config_name='default_inner_features.yaml')
def main(predict_config: OmegaConf):
    try:
        if sys.platform != 'win32':
            register_debug_signal_handlers()  # kill -10 <pid> will result in traceback dumped into log

        device = torch.device(predict_config.device)

        train_config_path = os.path.join(predict_config.model.path, 'config.yaml')
        with open(train_config_path, 'r') as f:
            train_config = OmegaConf.create(yaml.safe_load(f))

        checkpoint_path = os.path.join(predict_config.model.path, 'models', predict_config.model.checkpoint)
        model = load_checkpoint(train_config, checkpoint_path, strict=False)
        model.freeze()
        model.to(device)

        assert isinstance(model, DefaultInpaintingTrainingModule)
        assert isinstance(getattr(model.generator, 'model', None)

        if not predict_config.indir.endswith('/'):
            predict_config.indir += '/'

        dataset = make_default_val_dataset(predict_config.indir, **predict_config.dataset)

        max_level = max(predict_config.levels)

        with torch.no_grad():
            for img_i in tqdm.trange(len(dataset)):
                mask_fname = dataset.mask_filenames[img_i]
                cur_out_fname = os.path.join(predict_config.outdir)
                os.makedirs(os.path.dirname(cur_out_fname), exist_ok=True)

                batch = move_to_device(default_collate([dataset[img_i]]), device)

                img = batch['image']
                mask = batch['mask']
                mask[:] = 0
                mask_h, mask_w = mask.shape[-2:]
                mask[:, :,
                    mask_h // 2 - predict_config.hole_radius : mask_h // 2 + predict_config.hole_radius,
                    mask_w // 2 - predict_config.hole_radius : mask_w // 2 + predict_config.hole_radius] = 1

                masked_img = torch.cat([img * (1 - mask), mask], dim=1)

                feats = masked_img
                for level_i, level in enumerate(model.generator.model):
                    feats = level(feats)
                    if level_i in predict_config.levels:
                        cur_feats = torch.cat([f for f in feats if torch.is_tensor(f)], dim=1) \
                            if isinstance(feats, tuple) else feats

                        if predict_config.slice_channels:
                            cur_feats = cur_feats[:, slice(*predict_config.slice_channels)]

                        cur_feat = cur_feats.pow(2).mean(1).pow(0.5).clone()
                        cur_feat -= cur_feat.min()
                        cur_feat /= cur_feat.std()
                        cur_feat = cur_feat.clamp(0, 1) / 1
                        cur_feat = cur_feat.cpu().numpy()[0]
                        cur_feat *= 255
                        cur_feat = np.clip(cur_feat, 0, 255).astype('uint8')
                        cv2.imwrite(cur_out_fname + f'_lev{level_i:02d}_norm.png', cur_feat)

                        # for channel_i in predict_config.channels:
                        #
                        #     cur_feat = cur_feats[0, channel_i].clone().detach().cpu().numpy()
                        #     cur_feat -= cur_feat.min()
                        #     cur_feat /= cur_feat.max()
                        #     cur_feat *= 255
                        #     cur_feat = np.clip(cur_feat, 0, 255).astype('uint8')
                        #     cv2.imwrite(cur_out_fname + f'_lev{level_i}_ch{channel_i}.png', cur_feat)
                    elif level_i >= max_level:
                        break
    except KeyboardInterrupt:
        LOGGER.warning('Interrupted by user')
    except Exception as ex:
        LOGGER.critical(f'Prediction failed due to {ex}:\n{traceback.format_exc()}')
        sys.exit(1)


if __name__ == '__main__':
    main()

            </code></pre>
        </section>
    </main>

    <!-- 引入交互脚本 -->
    <script src="static/js/project-interactions.js"></script>

    <!-- Highlight.js 样式与脚本 -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>